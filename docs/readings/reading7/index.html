<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta
      name="description"
      content="Fall 2020 - Harvard University, Institute for Applied Computational Science. Reading Discussion 7"
    />
    <meta name="author" content="Andrea Porelli" />
<meta
  name="keywords"
  content="Language Modelling, Attention, Transformers"
/>

    <!-- Bootstrap CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css"
      integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB"
      crossorigin="anonymous"
    />

    <link
      rel="stylesheet"
      href="https://use.fontawesome.com/releases/v5.2.0/css/all.css"
      integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ"
      crossorigin="anonymous"
    />

    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Condensed|Roboto:300,400,700"
      rel="stylesheet"
    />

    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css"
    />

    <link
      rel="stylesheet"
      href="../../style/tipuesearch/tipuesearch.css"
    />

    <link
      rel="shortcut icon"
      type="image/x-icon"
      href="../../style/images/favicon.ico"
    />
    <link rel="stylesheet" href="../../style/css/iacs.css" />

    <title>Harvard AC295 | Reading Discussion 7</title>

    <style>
      .navbar {
        background-color: #6996A0
      }
    </style>
  </head>
  <body>
<nav class="navbar navbar-dark navbar-expand-md">
  <div class="container">
    <a class="navbar-brand" href="../..">
      <img
        class="navbar-brand-logo"
        src="../../style/images/logo.png"
      />
      <h3 class="course-title">AC295</h3>
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarsDefault"
      aria-controls="navbarsDefault"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarsDefault">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="../../pages/syllabus.html">Syllabus</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../pages/calendars.html">Calendars</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../pages/schedule.html">Schedule</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../pages/materials.html">Materials</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../pages/projects.html">Projects</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../pages/faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../pages/resources.html">Resources</a>
        </li>
        <form
          class="form-inline my-2"
          action="../../search.html"
          onsubmit="return validateForm(this.elements['q'].value);"
        >
          <div class="input-group input-group-sm">
            <input
              class="form-control"
              type="text"
              name="q"
              placeholder="Search Topic"
            />
            <div class="input-group-append">
              <button class="btn btn-default" type="submit">
                <i class="fas fa-search"></i>
              </button>
            </div>
          </div>
        </form>
      </ul>
    </div>
    <!-- .collapse navbar-collapse -->
  </div>
  <!-- .container -->
</nav>
    <main id="content" class="container">
 <h1>Reading Discussion 7</h1>
<p>
  Key Word(s):   <a href="../../pages/materials.html#Language Modelling">Language Modelling</a
  >,   <a href="../../pages/materials.html#Attention">Attention</a
  >,   <a href="../../pages/materials.html#Transformers">Transformers</a
  > </p>
 <br />
<hr />
 <h2>Selected Readings</h2>
<ul>
<li>
<h1>Expository</h1>
</li>
<li>
<p>Adam Kosiorek: <a href="http://akosiorek.github.io/ml/2017/10/14/visual-attention.html">Attention in Neural Networks and How to Use It</a>  </p>
</li>
<li>
<p>Lilian Weng: <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">Attention? Attention!</a></p>
</li>
<li>
<p>Jay Alammar: <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> and <a href="http://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a> and <a href="https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">Visual guide to using BERT for the first time.</a></p>
</li>
<li>
<p><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">Annotated Transformer</a></p>
</li>
<li>
<p>Yannic Kilcher's videos explaining the <a href="https://www.youtube.com/watch?v=iDulhoQ2pro">transformers</a> and <a href="https://www.youtube.com/watch?v=-9evrZnBorM">BERT</a> and <a href="https://www.youtube.com/watch?v=SY5PvZrJhLE">GPT-3</a> papers. </p>
</li>
<li>
<p>Chris McCormick's <a href="https://www.youtube.com/playlist?list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6">BERT Research Series</a>. A YouTube playlist covering word embeddings, attention, positional encodings, masked language models and fine-tuning.</p>
</li>
</ul>
<p><br></p>
<ul>
<li>
<h1>Use Cases</h1>
</li>
<li>
<p><a href="https://spacy.io/">spaCy</a>. An excellent library for using language models in production. <br/>
        - <a href="https://explosion.ai/blog/spacy-transformers">spaCy meets Transformers: Fine-tune BERT, XLNet and GPT-2</a>. </p>
</li>
<li>
<p><a href="https://www.youtube.com/playlist?list=PLBmcuObd5An4UC6jvK_-eSl6jCvP1gwXc">spaCy IRL 2019</a></p>
</li>
</ul>
<!-- A guide on how to use [Hugging Face](https://huggingface.co/)'s [pre-trained NLP models](https://github.com/huggingface/transformers) in spaCy.
- [spaCy IRL 2019](https://www.youtube.com/playlist?list=PLBmcuObd5An4UC6jvK_-eSl6jCvP1gwXc). Conference presentations covering the use of NLP models in industry, including [conversational AI assistants](https://www.youtube.com/watch?v=1jI0mTcNRUU&list=PLBmcuObd5An4UC6jvK_-eSl6jCvP1gwXc); [scientific and biomedical text](https://www.youtube.com/watch?v=2_HSKDALwuw&list=PLBmcuObd5An4UC6jvK_-eSl6jCvP1gwXc); [finance](https://www.youtube.com/watch?v=rdmaR4WRYEM&list=PLBmcuObd5An4UC6jvK_-eSl6jCvP1gwXc); and [asset management](https://www.youtube.com/watch?v=kX14Ycieju8&list=PLBmcuObd5An4UC6jvK_-eSl6jCvP1gwXc). -->

<ul>
<li>
<p><a href="https://transformer.huggingface.co/">Write With Transformer</a>. <a href="https://huggingface.co">Hugging Face</a>'s interactive demonstration of GPT-2 and XLNET's predictive power. </p>
</li>
<li>
<p>Gwern Branden's <a href="https://www.gwern.net/GPT-3">GPT-3 page</a>. Discussions on how GPT-3 is programmed using prompts; its limitations; examples of poetry and prose generated in the style of famous authors, philosophers, etc.; its performance on logic and arithmetic tasks.
<br></p>
</li>
<li>
<h1>Research</h1>
</li>
<li>
<p><a href="https://arxiv.org/abs/1706.03762">Vaswani et al (2017), 'Attention is All you Need'</a>. Introduces the Transformer, the neural network architecture used by the most powerful language models. <a href="http://rush-nlp.com/">Sasha Rush</a> has an excellent <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">line-by-line PyTorch implementation</a> of this paper.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1810.04805">Devlin et al (2019), 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2005.14165.pdf">OpenAI (2020), 'Language Models are Few-Shot Learners' (GPT-3 paper)</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2009.06732.pdf">Efficient Transformers: A Survey</a></p>
</li>
<li><a href="https://arxiv.org/pdf/2007.14062.pdf">Big Bird: Transformers for Longer Sequences</a></li>
<li><a href="https://arxiv.org/pdf/1502.03044.pdf">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>
<li><a href="https://arxiv.org/pdf/1706.05137.pdf">One Model To Learn Them All</a></li>
<li><a href="https://arxiv.org/pdf/1905.05583.pdf">How to Fine-Tune BERT for Text Classification</a></li>
</ul>
<p><br>
* Next presentations, select from Research or Use Case</p>     </main>

<footer class="footer">
  <div class="container">
    <span class="text-muted">Copyright 2020 &copy;
      <a class="text-muted" href="https://iacs.seas.harvard.edu/">Institute for Applied Computational Science</a>
    </span>
  </div>
</footer>     <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
      integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js"
      integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T"
      crossorigin="anonymous"
    ></script>
  </body>
</html>